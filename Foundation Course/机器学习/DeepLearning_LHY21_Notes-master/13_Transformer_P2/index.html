
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="hlx的个人网站">
      
      
        <meta name="author" content="lix">
      
      
        <link rel="canonical" href="https://a-hlx.github.io/Foundation%20Course/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/DeepLearning_LHY21_Notes-master/13_Transformer_P2/">
      
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.6">
    
    
      
        <title>Transformer P2_Decoder - hlx个人网站</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.558e4712.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.2505c338.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../mkdocs/css/no-footer.css">
    
      <link rel="stylesheet" href="../../../../mkdocs/css/unordered-list-symbols.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#transformer-p2_decoder" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../../.." title="hlx个人网站" class="md-header__button md-logo" aria-label="hlx个人网站" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            hlx个人网站
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Transformer P2_Decoder
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="切换至夜间模式"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="切换至夜间模式" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
            </label>
          
        
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="切换至日间模式"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="切换至日间模式" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/a-hlx/a-hlx.github.io" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    a-hlx.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../" class="md-tabs__link">
        Foundation Course
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../cornerstone/" class="md-tabs__link">
        cornerstone
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../LECTURE/" class="md-tabs__link">
        augment
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../BLOG/" class="md-tabs__link">
        Blog
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../REPRODUCE/" class="md-tabs__link">
        转载
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../../ABOUT/" class="md-tabs__link">
        关于
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="hlx个人网站" class="md-nav__button md-logo" aria-label="hlx个人网站" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    hlx个人网站
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/a-hlx/a-hlx.github.io" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    a-hlx.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
        
          
            
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../">Foundation Course</a>
          
            <label for="__nav_1">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Foundation Course" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Foundation Course
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_1_2" type="checkbox" id="__nav_1_2" >
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_1_2" tabindex="0" aria-expanded="false">
          python
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="python" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_2">
          <span class="md-nav__icon md-icon"></span>
          python
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_1_2_1" type="checkbox" id="__nav_1_2_1" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_1_2_1" tabindex="0" aria-expanded="false">
          python基础
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="python基础" data-md-level="3">
        <label class="md-nav__title" for="__nav_1_2_1">
          <span class="md-nav__icon md-icon"></span>
          python基础
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day01%20python%E5%9F%BA%E7%A1%80/" class="md-nav__link">
        01 绪论
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day02%20if%E5%88%A4%E6%96%AD%E4%B8%8E%E5%BE%AA%E7%8E%AF/" class="md-nav__link">
        02 if判断与循环
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day03%20%E5%AE%B9%E5%99%A8/" class="md-nav__link">
        03 容器
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day04%20%E5%AD%97%E5%85%B8%E4%B8%8E%E5%87%BD%E6%95%B0/" class="md-nav__link">
        04 字典与函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day05%20%E5%87%BD%E6%95%B0/" class="md-nav__link">
        05 函数
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day06%20%E5%87%BD%E6%95%B0%E4%B8%8E%E6%96%87%E4%BB%B6/" class="md-nav__link">
        06 函数与文件
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day07%20%E6%96%87%E4%BB%B6/" class="md-nav__link">
        07 文件
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day08%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1_%E5%B0%81%E8%A3%85/" class="md-nav__link">
        08 面向对象_封装
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day09%20%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/" class="md-nav__link">
        09 面向对象
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Python/python%E5%9F%BA%E7%A1%80/Day10%20%E5%BC%82%E5%B8%B8%E4%B8%8E%E6%A8%A1%E5%9D%97/" class="md-nav__link">
        10 异常与模块
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_1_3" type="checkbox" id="__nav_1_3" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_1_3" tabindex="0" aria-expanded="false">
          MATLAB
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="MATLAB" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_3">
          <span class="md-nav__icon md-icon"></span>
          MATLAB
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/02Array_Operation/" class="md-nav__link">
        02Array_Operation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/03Structured_Programming_%26_Function/" class="md-nav__link">
        03Structured_Programming_&_Function
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/04Data_Structure_%26_File_Access/" class="md-nav__link">
        04Data_Structure_&_File_Access
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/05Basic_Plotting/" class="md-nav__link">
        05Basic_Plotting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/06Advanced_Plotting/" class="md-nav__link">
        06Advanced_Plotting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/08Image_Processing%20I/" class="md-nav__link">
        08Image_Processing I
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/09Image_Processing%20II/" class="md-nav__link">
        09Image_Processing II
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/10Integration_%26_Differentiation/" class="md-nav__link">
        10Integration_&_Differentiation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/11Root_Finding/" class="md-nav__link">
        11Root_Finding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/12Linear_Equations/" class="md-nav__link">
        12Linear_Equations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/13Statistics_%26_Data_Analysis/" class="md-nav__link">
        13Statistics_&_Data_Analysis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/14Curve_Fitting_%26_Interpolation/" class="md-nav__link">
        14Curve_Fitting_&_Interpolation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MATLAB/%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E6%95%B0%E5%80%BC%E8%A7%A3/" class="md-nav__link">
        微分方程数值解
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_1_4" type="checkbox" id="__nav_1_4" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_1_4" tabindex="0" aria-expanded="false">
          MYSQL
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="MYSQL" data-md-level="2">
        <label class="md-nav__title" for="__nav_1_4">
          <span class="md-nav__icon md-icon"></span>
          MYSQL
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/%E7%9B%AE%E5%BD%95/" class="md-nav__link">
        00.目录
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/01.mysql%E5%AE%89%E8%A3%85/" class="md-nav__link">
        01.mysql安装
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/02.%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/" class="md-nav__link">
        02.数据类型
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/03.%E5%BA%93%E5%92%8C%E6%95%B0%E6%8D%AE%E8%A1%A8/" class="md-nav__link">
        03.库和数据表
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/04.%E8%A1%A8%E7%9A%84%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/" class="md-nav__link">
        04.表的增删改查
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/05.%E8%A1%A8%E7%9A%84%E7%BB%BC%E5%90%88%E6%9F%A5%E8%AF%A2/" class="md-nav__link">
        05.表的综合查询
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/06.%E7%B4%A2%E5%BC%95/" class="md-nav__link">
        06.索引
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/07.%E4%BA%8B%E5%8A%A1/" class="md-nav__link">
        07.事务
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/08.mysql%E7%94%A8%E6%88%B7%E4%B8%8E%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/" class="md-nav__link">
        08.mysql用户与权限管理
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/09.mysql%E4%BC%98%E5%8C%96/" class="md-nav__link">
        09.mysql优化
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/10.mysql%E4%BC%98%E5%8C%96%E5%88%86%E6%9E%90/" class="md-nav__link">
        10.mysql优化分析
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/11.%E8%A1%A8%E5%88%86%E5%8C%BA/" class="md-nav__link">
        11.表分区
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/12.mysql%E9%9B%86%E7%BE%A4/" class="md-nav__link">
        12.mysql集群
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/13.%E5%BC%80%E5%8F%91%E4%B8%AD%E6%AF%94%E8%BE%83%E5%B0%91%E7%94%A8%E7%9A%84%E5%8A%9F%E8%83%BD/" class="md-nav__link">
        13.开发中比较少用的功能
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/14.%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%BC%E5%85%A5%E5%AF%BC%E5%87%BA/" class="md-nav__link">
        14.数据库导入导出
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/15.%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%92%8C%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%AE%89%E5%85%A8%E4%BC%A0%E8%BE%93%E6%95%B0%E6%8D%AE/" class="md-nav__link">
        15.客户端和服务端安全传输数据
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../MySQL/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" class="md-nav__link">
        常见问题
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
        
          
            
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../../cornerstone/">cornerstone</a>
          
            <label for="__nav_2">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="cornerstone" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          cornerstone
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" >
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_2_2" tabindex="0" aria-expanded="false">
          Git
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Git" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          Git
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../cornerstone/Git/10%20%E4%B8%AA%E8%8A%82%E7%9C%81%E6%97%B6%E9%97%B4%E5%92%8C%E6%94%B9%E5%96%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%9A%84%20Git%20%E6%8A%80%E5%B7%A7/" class="md-nav__link">
        Git技巧
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../cornerstone/Git/Git%28%E5%88%86%E5%B8%83%E5%BC%8F%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%E5%B7%A5%E5%85%B7%29/" class="md-nav__link">
        Git基础
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../cornerstone/Git/git%E9%80%9F%E6%9F%A5/" class="md-nav__link">
        Git速查
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_2_3" type="checkbox" id="__nav_2_3" >
      
      
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_2_3" tabindex="0" aria-expanded="false">
          Markdown
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Markdown" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          Markdown
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../cornerstone/Markdown/markdown/" class="md-nav__link">
        Markdown讲座
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../cornerstone/Markdown/vscode-extension/" class="md-nav__link">
        VSCode及插件安装
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../cornerstone/Markdown/grammars/" class="md-nav__link">
        Markdown语法初学习
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../cornerstone/Markdown/ExMark-spec-zh.txt" class="md-nav__link">
        TODO ExMark规范
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../cornerstone/Markdown/MarkDown%E8%B6%85%E7%BA%A7%E6%95%99%E7%A8%8B%20Obsidian%E7%89%88%202022.1.12/" class="md-nav__link">
        MarkDown教程Ob版
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
        
          
            
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../../LECTURE/">augment</a>
          
            <label for="__nav_3">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="augment" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          augment
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_3_2" type="checkbox" id="__nav_3_2" >
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3_2" tabindex="0" aria-expanded="false">
          Linux
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Linux" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_2">
          <span class="md-nav__icon md-icon"></span>
          Linux
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LECTURE/Linux/linux/" class="md-nav__link">
        Linux讲座
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../LECTURE/Linux/commands-concise/" class="md-nav__link">
        命令行入门精简版
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
        
          
            
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../../BLOG/">Blog</a>
          
            <label for="__nav_4">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="Blog" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Blog
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" >
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_2" tabindex="0" aria-expanded="false">
          software
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="software" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          software
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/software/%E5%85%8D%E8%B4%B9%E6%BF%80%E6%B4%BBTypora/" class="md-nav__link">
        免费激活Typora
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/software/Obsidian%E4%BB%8B%E7%BB%8D/" class="md-nav__link">
        Obsidian介绍
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" >
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_3" tabindex="0" aria-expanded="false">
          Fun learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Fun learning" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          Fun learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/Fun%20learning/ChatGPT%E4%B8%AD%E6%96%87%E8%B0%83%E6%95%99%E6%8C%87%E5%8D%97/" class="md-nav__link">
        ChatGPT中文调教指南
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_4_4" type="checkbox" id="__nav_4_4" >
      
      
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_4" tabindex="0" aria-expanded="false">
          速查表
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="速查表" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_4">
          <span class="md-nav__icon md-icon"></span>
          速查表
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/bash/" class="md-nav__link">
        bash
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/c/" class="md-nav__link">
        c
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/cmd/" class="md-nav__link">
        cmd
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/docker/" class="md-nav__link">
        docker
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/emoji/" class="md-nav__link">
        emoji
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/git/" class="md-nav__link">
        git
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/github-actions/" class="md-nav__link">
        github-actions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/github/" class="md-nav__link">
        github
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/gitlab-ci/" class="md-nav__link">
        gitlab-ci
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/gitlab/" class="md-nav__link">
        gitlab
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/gmail/" class="md-nav__link">
        gmail
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/html-char/" class="md-nav__link">
        html-char
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/html/" class="md-nav__link">
        html
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/java/" class="md-nav__link">
        java
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/javascript/" class="md-nav__link">
        javascript
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/latex/" class="md-nav__link">
        latex
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/markdown/" class="md-nav__link">
        markdown
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/matlab/" class="md-nav__link">
        matlab
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/mysql/" class="md-nav__link">
        mysql
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/pycharm/" class="md-nav__link">
        pycharm
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/python/" class="md-nav__link">
        python
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/pytorch/" class="md-nav__link">
        pytorch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/ssh/" class="md-nav__link">
        ssh
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../BLOG/%E9%80%9F%E6%9F%A5%E8%A1%A8/vscode/" class="md-nav__link">
        vscode
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
        
          
            
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../../REPRODUCE/">转载</a>
          
            <label for="__nav_5">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="转载" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          转载
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../REPRODUCE/how-to-ask-questions-the-smart-way/" class="md-nav__link">
        提问的智慧
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../REPRODUCE/tim-cook-at-duke/" class="md-nav__link">
        Tim Cook's Commencement Address at Duke University, 2018
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../REPRODUCE/my-best-teacher/" class="md-nav__link">
        我最好的老师
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
        
          
            
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../../../../ABOUT/">关于</a>
          
            <label for="__nav_6">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" aria-label="关于" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          关于
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../ABOUT/help/" class="md-nav__link">
        文章编写帮助
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../ABOUT/build/" class="md-nav__link">
        网站构建
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../ABOUT/test/" class="md-nav__link">
        测试文档
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#decoder-autoregressive-at" class="md-nav__link">
    Decoder – Autoregressive (AT)
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#decoder-non-autoregressive-nat" class="md-nav__link">
    Decoder – Non-autoregressive (NAT)
  </a>
  
    <nav class="md-nav" aria-label="Decoder – Non-autoregressive (NAT)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#at-vs-nat" class="md-nav__link">
    AT v.s. NAT
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#encoder-decoder" class="md-nav__link">
    Encoder-Decoder
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training" class="md-nav__link">
    Training
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tips" class="md-nav__link">
    Tips
  </a>
  
    <nav class="md-nav" aria-label="Tips">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#copy-mechanism" class="md-nav__link">
    Copy Mechanism
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#summarization" class="md-nav__link">
    Summarization
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#guided-attention" class="md-nav__link">
    Guided Attention
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#beam-search" class="md-nav__link">
    Beam Search
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#optimizing-evaluation-metrics" class="md-nav__link">
    Optimizing Evaluation Metrics?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scheduled-sampling" class="md-nav__link">
    Scheduled Sampling
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  
  



  
  



<h1 id="transformer-p2_decoder">Transformer P2_Decoder<a class="headerlink" href="#transformer-p2_decoder" title="Permanent link">&para;</a></h1>
<h2 id="decoder-autoregressive-at">Decoder – Autoregressive (AT)<a class="headerlink" href="#decoder-autoregressive-at" title="Permanent link">&para;</a></h2>
<p>Decoder其实有两种,接下来会花比较多时间介绍,比较常见的 ==Autoregressive  Decoder==,这个 Autoregressive 的 Decoder,是怎麼运作的</p>
<p>用<strong>语音辨识</strong>,来当作例子来说明,或用在作业裡面的<strong>机器翻译</strong>,其实是一模一样的,你只是把输入输出,改成不同的东西而已</p>
<p><strong>语音辨识</strong>就是<strong>输入一段声音,输出一串文字</strong>,你会把一段声音输入给 Encoder,比如说你对机器说,机器学习,机器收到一段声音讯号,声音讯号 进入 Encoder以后,输出会是什麼,输出会变成一排 Vector</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505192814682.png" alt="image-20210505192814682" style="zoom: 50%;" /></p>
<p><strong>Encoder</strong> 做的事情,就是<strong>输入一个 Vector Sequence</strong>,<strong>输出另外一个 Vector Sequence</strong></p>
<p>接下来,就轮到 Decoder 运作了,<strong>Decoder 要做的事情就是產生输出</strong>,也就是<strong>產生语音辨识的结果</strong>, Decoder 怎麼產生这个语音辨识的结果</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505193416391.png" alt="image-20210505193416391" style="zoom:50%;" /></p>
<p>Decoder 做的事情,就是<strong>把 Encoder 的输出先读进去</strong>,至於怎麼读进去,这个我们等一下再讲 我们先,你先假设 Somehow 就是有某种方法,把 Encoder 的输出读到 Decoder 裡面,这步我们等一下再处理</p>
<p>Decoder 怎麼產生一段文字</p>
<p>首先,你要先给它一个特殊的符号,这个特殊的符号,代表开始,在助教的投影片裡面,是写 Begin Of Sentence,缩写是 BOS</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505193652691.png" alt="image-20210505193652691" style="zoom:50%;" /></p>
<p>就是 Begin 的意思,这个是一个 Special 的 Token,你就是在你的个 Lexicon 裡面,你就在你可能,本来 Decoder 可能產生的文字裡面,多加一个特殊的字,这个字就代表了 BEGIN,代表了开始这个事情</p>
<p>在这个机器学习裡面,假设你要处理 NLP 的问题,<strong>每一个 Token,你都可以把它用一个 One-Hot 的 Vector 来表示</strong>,One-Hot Vector 就其中一维是 1,其他都是 0,所以 <strong>BEGIN 也是用 One-Hot Vector 来表示</strong>,其中一维是 1,其他是 0</p>
<p>接下来Decoder 会<strong>吐出一个向量,这个 Vector 的长度很长,跟你的 Vocabulary 的 Size 是一样的</strong></p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505194403395.png" alt="image-20210505194403395" style="zoom:50%;" /></p>
<p>==Vocabulary Size==则是什麼意思</p>
<p>你就先想好说,你的 Decoder <strong>输出的单位</strong>是什麼,假设我们今天做的是中文的语音辨识,我们 Decoder 输出的是中文,你这边的 Vocabulary 的 Size ,可能就是中文的方块字的数目</p>
<p><strong>不同的字典,给你的数字可能是不一样的</strong>,常用的中文的方块字,大概两 三千个,一般人,可能认得的四 五千个,在更多都是罕见字 冷僻的字,所以你就看看说,你要让你的 Decoder,输出哪些可能的中文的方块字,你就把它列在这边</p>
<p>举例来说,你觉得这个 Decoder,能够输出常见的 3000 个方块字就好了,就把它列在这个地方,不同的语言,它输出的单位 不见不会不一样,这个取决於你对个语言的理解</p>
<p>比如说英文,你可以选择输出<strong>字母的 A 到 Z</strong>,输出英文的字母,但你可能会觉得字母这个单位太小了,有人可能会选择输出<strong>英文的词汇</strong>,英文的词汇是用空白作為间隔的,但如果都用词汇当作输出,又太多了</p>
<p>所以你会发现,刚才在助教的投影片裡面,助教说他是用 Subword 当作英文的单位,就有一些方法,可以把英文的字首字根切出来,拿字首字根当作单位,如果中文的话,我觉得就比较单纯,通常今天你可能就用中文的这个方块字,来当作单位</p>
<p>每一个中文的字,都会对应到一个数值,因為在<strong>產生这个向量之前,你通常会先跑一个 Softmax</strong>,就跟做分类一样,所以这一个向量裡面的分数,它是一个 Distribution,也就是,它这个向量裡面的值,它全部加起来,总和 会是 1</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505195003941.png" alt="image-20210505195003941" style="zoom: 67%;" /></p>
<p><strong>分数最高的一个中文字,它就是最终的输出</strong></p>
<p>在这个例子裡面,机的分数最高,所以机,就当做是这个 Decoder 第一个输出</p>
<p>然后接下来,你<strong>把“机”当做是 Decoder 新的 Input</strong>,原来 Decoder 的 Input,只有 BEGIN 这个特别的符号,现在它除了 BEGIN 以外,它还有“机”作為它的 Input</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505195340257.png" alt="image-20210505195340257" style="zoom:50%;" /></p>
<p>所以 Decoder <strong>现在它有两个输入</strong></p>
<ul>
<li>一个是 <strong>BEGIN</strong> 这个符号</li>
<li>一个是<strong>“机”</strong></li>
</ul>
<p>根据这两个输入,它输出一个蓝色的向量,根据这个蓝色的向量裡面,给每一个中文的字的分数,我们会决定第二个输出，哪一个字的分数最高,它就是输出,假设"器"的分数最高,<strong>"器"就是输出</strong></p>
<p>然后现在 Decoder </p>
<ul>
<li>看到了 BEGIN</li>
<li>看到了"机" </li>
<li>看到了"器"</li>
</ul>
<p>它接下来,还要再决定接下来要输出什麼,它可能,就输出"学",这一个过程就反覆的持续下去</p>
<p>所以现在 Decode </p>
<ul>
<li>
<p>看到了 BEGIN </p>
</li>
<li>
<p>看到了"机" </p>
</li>
<li>
<p>看到了"器"</p>
</li>
<li>
<p>还有"学"</p>
</li>
</ul>
<p><strong>Encoder 这边其实也有输入</strong>,等一下再讲 Encoder 的输入,Decoder 是怎麼处理的,</p>
<p>所以 Decoder 看到 Encoder 这边的输入,看到"机"  看到"器" 看到"学",决定接下来输出一个向量,这个向量裡面,"习"这个中文字的分数最高的,所以它就输出"习"</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505203022207.png" alt="image-20210505203022207" style="zoom:50%;" /></p>
<p><strong>然后这个 Process ,就反覆持续下去</strong>,这边有一个关键的地方,我们特别用红色的虚线把它标出来</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505203437172.png" alt="image-20210505203437172" style="zoom:67%;" /></p>
<p>也就是说 Decoder 看到的输入,其实是它在前一个时间点,自己的输出,<strong>Decoder 会把自己的输出,当做接下来的输入</strong></p>
<p>如果Decoder 看到<strong>错误的输入</strong>,让 Decoder 看到自己產生出来的错误的输入,再被 Decoder 自己吃进去,会不会造成 ==Error Propagation== 的问题</p>
<p>Error Propagation 的问题就是,<strong>一步错 步步错</strong>这样,就是在这个地方,如果不小心把机器的“器”,不小心写成天气的"气",会不会接下来就整个句子都坏掉了,都没有办法再產生正确的词汇了?</p>
<p>有可能,这个等一下,我们最后会稍微讲一下,这个问题要怎麼处理,我们现在,先无视这个问题,继续走下去</p>
<p>我们来看一下这个 <strong>Decoder内部的结构</strong>长什麼样子</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505203958558.png" alt="image-20210505203958558" style="zoom:50%;" /></p>
<p>那我们这边,<strong>把 Encoder 的部分先暂时省略掉</strong>,那在 Transformer 裡面,Decoder 的结构,长得是这个样子的,看起来有点复杂,比 Encoder 还稍微复杂一点,</p>
<p>那我们现在先把 Encoder 跟 Decoder 放在一起</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505204215642.png" alt="image-20210505204215642" style="zoom:50%;" /></p>
<p>稍微比较一下它们之间的差异,那你会发现说,如果我们把 Decoder 中间这一块,<strong>中间这一块把它盖起来,其实 Encoder 跟 Decoder,并没有那麼大的差别</strong></p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505204300084.png" alt="image-20210505204300084" style="zoom:50%;" /></p>
<p>你看 Encoder 这边,Multi-Head Attention,然后 Add &amp; Norm,Feed Forward,Add &amp; Norm,重复 N 次,Decoder 其实也是一样</p>
<p>当我们把中间这一块遮起来以后,我们等一下再讲,遮起来这一块裡面做了什麼事,但当我们把中间这块遮起来以后,欸 那 Decoder 也是,有一个 Multi-Head Attention,Add &amp; Norm,然后 Feed Forward,然后 Add &amp; Norm,所以 Encoder 跟 Decoder,其实并没有非常大的差别,除了中间这一块不一样的地方,</p>
<p>那只是最后,我们可能会再做一个 Softmax,使得它的输出变成一个机率,那这边有一个<strong>稍微不一样的地方</strong>是,在 Decoder 这边,Multi-Head Attention 这一个 Block 上面,还<strong>加了一个 ==Masked==</strong>,</p>
<p>这个 Masked 的意思是这样子的,这是我们原来的 Self-Attention</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505204547594.png" alt="image-20210505204547594" style="zoom: 67%;" /></p>
<p>Input 一排 Vector,Output 另外一排 Vector,这一排 Vector <strong>每一个输出</strong>,都要看过完整的 Input 以后,才做决定,所以输出 <span class="arithmatex">\(b^1\)</span> 的时候,其实是根据 <span class="arithmatex">\(a^1\)</span> 到 <span class="arithmatex">\(a^4\)</span> 所有的资讯,去输出 <span class="arithmatex">\(b^1\)</span></p>
<p>当我们把 Self-Attention,转成 Masked Attention 的时候,它的不同点是,现在我们不能再看右边的部分,也就是產生 <span class="arithmatex">\(b^1\)</span> 的时候,我们只能考虑 <span class="arithmatex">\(a^1\)</span> 的资讯,你不能够再考虑 <span class="arithmatex">\(a^2\)</span> <span class="arithmatex">\(a^3\)</span> <span class="arithmatex">\(a^4\)</span></p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505205155734.png" alt="image-20210505205155734" style="zoom:50%;" /></p>
<p>產生 <span class="arithmatex">\(b^2\)</span> 的时候,你只能考虑 <span class="arithmatex">\(a^1\)</span> <span class="arithmatex">\(a^2\)</span> 的资讯,不能再考虑 <span class="arithmatex">\(a^3\)</span> <span class="arithmatex">\(a^4\)</span> 的资讯</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505205223197.png" alt="image-20210505205223197" style="zoom:50%;" /></p>
<p>產生 <span class="arithmatex">\(b^3\)</span> 的时候,你就不能考虑 <span class="arithmatex">\(a^4\)</span> 的资讯,</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505205307428.png" alt="image-20210505205307428" style="zoom:50%;" /></p>
<p>產生 <span class="arithmatex">\(b^4\)</span> 的时候,你可以用整个 Input Sequence 的资讯,这个就是 Masked 的 Self-Attention,</p>
<p>讲得更具体一点,你做的事情是,当我们要產生 <span class="arithmatex">\(b^2\)</span> 的时候,我们只拿第二个位置的 Query <span class="arithmatex">\(b^2\)</span>,去跟第一个位置的 Key,和第二个位置的 Key,去计算 Attention,第三个位置跟第四个位置,就不管它,不去计算 Attention</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505205618457.png" alt="image-20210505205618457" style="zoom:50%;" /></p>
<p>我们这样子不去管这个 <span class="arithmatex">\(a^2\)</span> 右边的地方,只考虑 <span class="arithmatex">\(a^1\)</span> 跟 <span class="arithmatex">\(a^2\)</span>,只考虑 <span class="arithmatex">\(q^1\)</span> <span class="arithmatex">\(q^2\)</span>,只考虑 <span class="arithmatex">\(k^1\)</span> <span class="arithmatex">\(k^2\)</span>,<span class="arithmatex">\(q^2\)</span> 只跟 <span class="arithmatex">\(k^1\)</span> 跟 <span class="arithmatex">\(k^2\)</span> 去计算 Attention,然后最后只计算 <span class="arithmatex">\(b^1\)</span> 跟 <span class="arithmatex">\(b^2\)</span> 的 Weighted Sum</p>
<p>然后当我们输出这个 <span class="arithmatex">\(b^2\)</span> 的时候,<span class="arithmatex">\(b^2\)</span> 就只考虑了 <span class="arithmatex">\(a^1\)</span> 跟 <span class="arithmatex">\(a^2\)</span>,就没有考虑到 <span class="arithmatex">\(a^3\)</span> 跟 <span class="arithmatex">\(a^4\)</span></p>
<p>那為什麼会这样,為什麼需要加 Masked </p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505205746128.png" alt="image-20210505205746128" style="zoom:50%;" /></p>
<p>这件事情其实非常地直觉:我们一开始 Decoder 的运作方式,它是<strong>一个一个输出</strong>,所以是先有 <span class="arithmatex">\(a^1\)</span> 再有 <span class="arithmatex">\(a^2\)</span>,再有 <span class="arithmatex">\(a^3\)</span> 再有 <span class="arithmatex">\(a^4\)</span></p>
<p><strong>这跟原来的 Self-Attention 不一样</strong>,原来的 Self-Attention,<span class="arithmatex">\(a^1\)</span> 跟 <span class="arithmatex">\(a^4\)</span> 是一次整个输进去你的 Model 裡面的,在我们讲 Encoder 的时候,Encoder 是一次把 <span class="arithmatex">\(a^1\)</span> 跟 <span class="arithmatex">\(a^4\)</span>,都整个都读进去</p>
<p>但是对 Decoder 而言,先有 <span class="arithmatex">\(a^1\)</span> 才有 <span class="arithmatex">\(a^2\)</span>,才有 <span class="arithmatex">\(a^3\)</span> 才有 <span class="arithmatex">\(a^4\)</span>,所以实际上,当你有 <span class="arithmatex">\(a^2\)</span>,你要计算 <span class="arithmatex">\(b^2\)</span> 的时候,你是没有 <span class="arithmatex">\(a^3\)</span> 跟 <span class="arithmatex">\(a^4\)</span> 的,所以你根本就没有办法把 <span class="arithmatex">\(a^3\)</span> <span class="arithmatex">\(a^4\)</span> 考虑进来</p>
<p>所以这就是為什麼,在那个 Decoder 的那个图上面,Transformer 原始的 Paper 特别跟你强调说,<strong>那不是一个一般的 Attention,这是一个 Masked 的 Self-Attention</strong>,意思只是想要告诉你说,Decoder 它的 Tokent,<strong>它输出的东西是一个一个產生的,所以它只能考虑它左边的东西,它没有办法考虑它右边的东西</strong></p>
<p>讲了 Decoder 的运作方式,但是这边,还有一个非常关键的问题,<strong>Decoder 必须自己决定,输出的 Sequence 的长度</strong></p>
<p>可是到底输出的 Sequence 的长度应该是多少,我们不知道</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505210300099.png" alt="image-20210505210300099" style="zoom:50%;" /></p>
<p>你没有办法轻易的从输入的 Sequence 的长度,就知道输出的 Sequence 的长度是多少,并不是说,输入是 4 个向量,输出一定就是 4 个向量</p>
<p>这边在这个例子裡面,输入跟输出的长度是一样的,但是你知道实际上在你真正的应用裡面,并不是这样,输入跟输出长度的关係,是非常复杂的,我们其实是期待机器可以自己学到,今天给它一个 Input Sequence 的时候,Output 的 Sequence 应该要多长</p>
<p>但在我们目前的这整个 Decoder的这个运作的机制裡面,<strong>机器不知道它什麼时候应该停下来</strong>,它產生完习以后,它还可以继续重复一模一样的 Process,就把习,当做输入,然后也许 Decoder ,就会接一个惯,然后接下来,就一直持续下去,<strong>永远都不会停下来</strong></p>
<p>这就让我想到推文接龙</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505210657053.png" alt="image-20210505210657053" style="zoom:50%;" /></p>
<p>我不知道大家知不到这是什麼,这是一个这个古老的民俗传统,流传在 PTT 上面,这个民俗传统是怎麼运作的,就有一个人,先推一个中文字,然后推一个超,然后接下来,就会有另外一个乡民,去推另外一个字,然后可以接上去的,所以就可以產生一排的词汇啦,一排字啦,就是超人正大中天外飞仙草,不知道在说些什麼,这个是 Process ,可以持续好几个月,都不停下来,我也不知道為什麼,那怎麼让这个 Process 停下来,那要怎麼让它停下来</p>
<p>要<strong>有人冒险去推一个断,推个断,它就停下来了</strong></p>
<p>所以我们要让 Decoder 做的事情,也是一样,要让它可以输出一个断,所以你要<strong>特别準备一个特别的符号</strong>,这个符号,就叫做断,我们这边,用 END 来表示这个特殊的符号</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505210756634.png" alt="image-20210505210756634" style="zoom:50%;" /></p>
<p>所以除了所有中文的方块字,还有 BEGIN 以外,你还要<strong>準备一个特殊的符号,叫做"断"</strong>,那其实在助教的程式裡面,它是把 BEGIN 跟 END,就是开始跟这个断,用同一个符号来表示</p>
<p>反正这个,这个 BEGIN 只会在输入的时候出现,断只会在输出的时候出现,所以在助教的程式裡面,如果你仔细研究一下的话,会发现说 END 跟 BEGIN,用的其实是同一个符号,但你用不同的符号,也是完全可以的,也完全没有问题</p>
<p>所以我们现在,当把"习"当作输入以后,就 Decoder 看到 Encoder 输出的这个 Embedding,看到了 "BEGIN",然后"机" "器" "学" "习"以后,看到这些资讯以后 它要知道说,这个语音辨识的结果已经结束了,不需要再產生更多的词汇了</p>
<p>它產生出来的向量END,就是断的那个符号,它的机率必须要是最大的,然后你就输出断这个符号,那整个运作的过程,整个 Decoder 產生 Sequence 的过程,就结束了</p>
<p>这个就是 ==Autoregressive  Decoder==,它运作的方式</p>
<h2 id="decoder-non-autoregressive-nat">Decoder – Non-autoregressive (NAT)<a class="headerlink" href="#decoder-non-autoregressive-nat" title="Permanent link">&para;</a></h2>
<p>用两页投影片,非常简短地讲一下,Non-Autoregressive 的 Model</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505213222908.png" alt="image-20210505213222908" style="zoom:50%;" /></p>
<p>Non-Autoregressive ,通常缩写成 NAT,所以有时候 Autoregressive 的 Model,也缩写成 AT,Non-Autoregressive 的 Model 是怎麼运作的</p>
<h3 id="at-vs-nat">AT v.s. NAT<a class="headerlink" href="#at-vs-nat" title="Permanent link">&para;</a></h3>
<p>这个 ==Autoregressive== 的 Model 是</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505213259792.png" alt="image-20210505213259792" style="zoom:67%;" /></p>
<p><strong>先输入 BEGIN</strong>,<strong>然后</strong>出现 w1,然后<strong>再</strong>把 w1 当做输入,<strong>再</strong>输出 w2,<strong>直到输出 END 為止</strong></p>
<p>那 ==NAT== 是这样,它<strong>不是依次產生</strong></p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505213441943.png" alt="image-20210505213441943" style="zoom:67%;" /></p>
<p>就假设我们现在產生是中文的句子,它不是依次產生一个字,它是<strong>一次把整个句子都產生出来</strong></p>
<p>NAT 的 Decoder<strong>可能吃的是一整排的 BEGIN 的 Token</strong>,你就把一堆一排 BEGIN 的 Token 都丢给它,让它一次產生一排 Token 就结束了</p>
<p>举例来说,如果你丢给它 4 个 BEGIN 的 Token,它就產生 4 个中文的字,变成一个句子,就结束了，所以它只要一个步骤,就可以完成句子的生成</p>
<p>这边你可能会问一个问题：刚才不是说不知道输出的长度应该是多少吗,那我们这边<strong>怎麼知道 BEGIN 要放多少个</strong>,当做 NAT Decoder 的收入？</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505214100885.png" alt="image-20210505214100885" style="zoom:50%;" /></p>
<p>没错 这件事没有办法很自然的知道,没有办法很直接的知道,所以有几个,所以有几个做法</p>
<ul>
<li>一个做法是,你<strong>另外learn一个 Classifier</strong>,这个 Classifier ,它吃 Encoder 的 Input,然后输出是一个数字,这个数字代表 Decoder 应该要输出的长度,这是一种可能的做法</li>
<li>另一种可能做法就是,你就不管三七二十一,<strong>给它一堆 BEGIN 的 Token</strong>,你就假设说,你现在输出的句子的长度,绝对不会超过 300 个字,你就假设一个句子长度的上限,然后 BEGIN ,你就给它 300 个 BEGIN,然后就会输出 300 个字嘛,然后,你再看看<strong>什麼地方输出 END</strong>,输出 END 右边的,就当做它没有输出,就结束了,这是另外一种处理 NAT 的这个 Decoder,它应该输出的长度的方法</li>
</ul>
<p>那 NAT 的 Decoder,它有什麼样的<strong>好处</strong>,</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505214412075.png" alt="image-20210505214412075" style="zoom:67%;" /></p>
<ul>
<li>
<p>它第一个好处是,<strong>并行化</strong>,这个 AT 的 Decoder,它在输出它的句子的时候,是一个一个一个字產生的,所以你有你的,假设要输出长度一百个字的句子,那你就需要做一百次的 Decode</p>
<p>但是 NAT 的 Decoder 不是这样,不管句子的长度如何,都是<strong>一个步骤就產生出完整的句子</strong>,所以在速度上,NAT 的 Decoder 它会跑得比,AT 的 Decoder 要快,那你可以想像说,这个 NAT Decoder 的想法显然是在,由这个 Transformer 以后,有这种 Self-Attention 的 Decoder 以后才有的</p>
<p>因為以前如果你是用那个 ==LSTM==,用 ==RNN== 的话,那你就算给它一排 BEGIN,它也没有办法同时產生全部的输出,它的输出还是一个一个產生的,所以在没有这个 Self-Attention 之前,只有 RNN,只有 LSTM 的时候,根本就不会有人想要做什麼 NAT 的 Decoder,不过自从有了 Self-Attention 以后,那 NAT 的 Decoder,现在就算是一个热门的研究的主题了</p>
</li>
<li>
<p>那 NAT 的 Decoder 还有另外一个好处就是,你比较能够<strong>控制它输出的长度</strong>,举语音合成為例,其实在语音合成裡面,NAT 的 Decoder 算是非常常用的,它并不是一个什麼稀罕 罕见的招数</p>
<p>比如说有,所以语音合成今天你都可以用,Sequence To Sequence 的模型来做,那最知名的,是一个叫做 ==Tacotron== 的模型,那它是 AT 的 Decoder</p>
<p>那有另外一个模型叫 ==FastSpeech==,那它是 NAT 的 Decoder,那 NAT 的 Decoder 有一个好处,就是你可以控制你输出的长度,那我们刚才说怎麼决定,NAT 的 Decoder 输出多长</p>
<p>你可能有一个 Classifier,决定 NAT 的 Decoder 应该输出的长度,那如果在做语音合成的时候,假设你现在突然想要让你的系统讲快一点,加速,那你就把那个 Classifier 的 Output 除以二,它讲话速度就变两倍快,然后如果你想要这个讲话放慢速度,那你就把那个 Classifier 输出的那个长度,它 Predict 出来的长度乘两倍,那你的这个 Decoder ,说话的速度就变两倍慢</p>
<p>所以你可以如果有这种 NAT 的 Decoder,那你有 Explicit 去 Model,Output  长度应该是多少的话,你就比较有机会去控制,你的 Decoder 输出的长度应该是多少,你就可以做种种的变化</p>
</li>
</ul>
<p>NAT 的 Decoder,最近它之所以是一个热门研究主题,就是它虽然表面上看起来有种种的厉害之处,尤其是平行化是它最大的优势,但是 <strong>NAT 的 Decoder ,它的 Performance,往往都不如 AT 的 Decoder</strong></p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505214728437.png" alt="image-20210505214728437" style="zoom:50%;" /></p>
<p>所以发现有很多很多的研究试图让,NAT 的 Decoder 的 Performance 越来越好,试图去逼近 AT 的 Decoder,不过今天你要让 NAT 的 Decoder,跟 AT 的 Decoder Performance 一样好,你<strong>必须要用非常多的 Trick</strong> 才能够办到,就 AT 的 Decoder 随便 Train 一下,NAT 的 Decoder 你要花很多力气,才有可能跟 AT 的 Performance 差不多</p>
<p>為什麼 NAT 的 Decoder Performance 不好,有一个问题我们今天就不细讲了,叫做 ==Multi-Modality== 的问题,那如果你想要这个深入了解 NAT,那就把之前上课,助教这个上课补充的内容,连结https://youtu.be/jvyKmU4OM3c放在这边给大家参考</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210505214815786.png" alt="image-20210505214815786" style="zoom:50%;" /></p>
<h2 id="encoder-decoder">Encoder-Decoder<a class="headerlink" href="#encoder-decoder" title="Permanent link">&para;</a></h2>
<p>接下来就要讲<strong>Encoder 跟 Decoder它们中间是怎麼传递资讯</strong>的了,也就是我们要讲,刚才我们刻意把它遮起来的那一块</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506103314101.png" alt="image-20210506103314101" style="zoom: 80%;" /></p>
<p>这块叫做 ==Cross Attention==,它是连接 Encoder 跟 Decoder 之间的桥樑,那这一块裡面啊,会发现有<strong>两个输入来自於 Encoder</strong>,Encoder 提供两个箭头,然后 <strong>Decoder 提供了一个箭头</strong>,所以从左边这两个箭头,Decoder 可以读到 Encoder 的输出</p>
<p>那这个模组实际上是怎麼运作的呢,那我们就实际把它运作的过程跟大家展示一下</p>
<p>这个是你的 Encoder</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506104141482.png" alt="image-20210506104141482" style="zoom: 50%;" /></p>
<p>输入一排向量,输出一排向量,我们叫它 <span class="arithmatex">\(a^1 a^2 a^3\)</span></p>
<p>接下来 轮到你的 Decoder,你的 Decoder 呢,会先吃 BEGIN 当做,BEGIN 这个 Special 的 Token,那 BEGIN 这个 Special 的 Token 读进来以后,你可能会经过 Self-Attention,这个 Self-Attention 是有做 Mask 的,然后得到一个向量,就是 Self-Attention 就算是有做 Mask,还是一样输入多少长度的向量,输出就是多少向量</p>
<p>所以输入一个向量 输出一个向量,然后接下来把这个向量呢,乘上一个矩阵做一个 Transform,得到一个 Query 叫做 q</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506105155338.png" alt="image-20210506105155338" style="zoom: 50%;" /></p>
<p>然后这边的 <span class="arithmatex">\(a^1 a^2 a^3\)</span> 呢,也都產生 Key,Key1 Key2 Key3,那把这个 q 跟 <span class="arithmatex">\(k^1 k^2 k^3\)</span>,去计算 Attention 的分数,得到 <span class="arithmatex">\(α_1 α_2 α_3\)</span>,当然你可能一样会做 Softmax,把它稍微做一下 Normalization,所以我这边加一个 ',代表它可能是做过 Normalization</p>
<p>接下来再把 <span class="arithmatex">\(α_1 α_2 α_3\)</span>,就乘上 <span class="arithmatex">\(v^1 v^2 v^3\)</span>,再把它 Weighted Sum 加起来会得到 v</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506105352521.png" alt="image-20210506105352521" style="zoom:50%;" /></p>
<p>那这一个 V,就是接下来会丢到 Fully-Connected 的,Network 做接下来的处理,那这个步骤就是 q 来自於 Decoder,k 跟 v 来自於 Encoder,这个步骤就叫做 Cross Attention</p>
<p>所以 <strong>Decoder 就是凭藉著產生一个 q,去 Encoder 这边抽取资讯出来,当做接下来的 Decoder 的,Fully-Connected 的 Network 的 Input</strong></p>
<p>当然这个,就现在假设產生第二个,第一个这个中文的字產生一个“机”,接下来的运作也是一模一样的</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506105747730.png" alt="image-20210506105747730" style="zoom: 50%;" /></p>
<p>输入 BEGIN 输入机,產生一个向量,这个向量一样乘上一个 Linear 的 Transform,得到 q',得到一个 Query,这个 Query 一样跟 <span class="arithmatex">\(k^1 k^2 k^3\)</span>,去计算 Attention 的分数,一样跟 <span class="arithmatex">\(v^1 v^2 v^3\)</span> 做 Weighted Sum 做加权,然后加起来得到 v',交给接下来 Fully-Connected Network 做处理</p>
<p>所以这就是Cross Attention 的运作的过程</p>
<p>也许有人会有<strong>疑问</strong>：那这个 Encoder 有很多层啊,Decoder 也有很多层啊,从刚才的讲解裡面好像听起来,这个 Decoder 不管哪一层,都是<strong>拿 Encoder 的最后一层的输出</strong>这样对吗？</p>
<p>对,<strong>在原始 Paper 裡面的实做是这样子</strong>,那一定要这样吗</p>
<p><strong>不一定要这样</strong>,你永远可以自己兜一些新的想法,所以我这边就是引用一篇论文告诉你说,也有人尝试不同的 Cross Attension 的方式</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506111930819.png" alt="image-20210506111930819" style="zoom: 67%;" /></p>
<p>Encoder 这边有很多层,Decoder 这边有很多层,為什麼 Decoder 这边每一层都一定要看,Encoder 的最后一层输出呢,能不能够有各式各样不同的连接方式,这完全可以当做一个研究的问题来 Study</p>
<h2 id="training">Training<a class="headerlink" href="#training" title="Permanent link">&para;</a></h2>
<p>已经清楚说 Input 一个 Sequence,是怎麼得到最终的输出,那接下来就进入训练的部分</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506121209178.png" alt="image-20210506121209178" style="zoom:50%;" /></p>
<p>刚才讲的都还只是,假设你模型训练好以后它是怎麼运作的,它是怎麼做 Testing 的,它是怎麼做 Inference 的,Inference 就是 Testing ，那是怎麼做训练的呢？</p>
<p>接下来就要讲怎麼做训练,那如果是做语音辨识,那你要有<strong>训练资料</strong>,你要收集一大堆的声音讯号,每一句声音讯号都要有工读生来听打一下,打出说它的这个对应的词汇是什麼</p>
<p><img alt="image-20210506122534592" src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506122534592.png" /></p>
<p>工读生听这段是机器学习,他就把机器学习四个字打出来,所以就知道说你的这个 Transformer,应该要学到 听到这段声音讯号,它的输出就是机器学习这四个中文字</p>
<p>那怎麼让机器学到这件事呢</p>
<p>我们已经知道说输入这段声音讯号,第一个应该要输出的中文字是“机”,所以今天当我们把 BEGIN,丢给这个 Encoder 的时候,它第一个输出应该要跟“机”越接近越好</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506122929142.png" alt="image-20210506122929142" style="zoom:50%;" /></p>
<p><strong>“机”这个字会被表示成一个 One-Hot 的 Vector</strong>,在这个 Vector 裡面,只有机对应的那个维度是 1,其他都是 0,这是正确答案,那我们的 Decoder,它的输出是一个 Distribution,是一个机率的分布,我们会希望这一个机率的分布,跟这个 One-Hot 的 Vector 越接近越好</p>
<p>所以你会去计算这个 Ground Truth,跟这个 Distribution 它们之间的 Cross Entropy,然后我们希望这个 ==Cross Entropy== 的值,越小越好</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506123013981.png" alt="image-20210506123013981" style="zoom:50%;" /></p>
<p>它就<strong>跟分类很像</strong>,刚才助教在讲解作业的时候也有提到这件事情,你可以想成每一次我们在產生,每一次 Decoder 在產生一个中文字的时候,其实就是做了一次分类的问题,中文字假设有四千个,那就是<strong>做有四千个类别的分类的问题</strong></p>
<p>所以实际上训练的时候这个样子,我们已经知道输出应该是“机器学习”这四个字,就告诉你的 Decoder ,现在你第一次的输出 第二次的输出,第三次的输出 第四次输出,应该分别就是“机” “器” “学”跟“习”,这四个中文字的 One-Hot Vector,我们<strong>希望我们的输出,跟这四个字的 One-Hot Vector 越接近越好</strong></p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506124154943.png" alt="image-20210506124154943" style="zoom:50%;" /></p>
<p>在训练的时候,每一个输出都会有一个 Cross Entropy,每一个输出跟 One-Hot Vector,跟它对应的正确答案都有一个 Cross Entropy,我们要希望所有的 Cross Entropy 的总和最小,越小越好</p>
<p>所以这边做了四次分类的问题,我们希望这些分类的问题,它总合起来的 Cross Entropy 越小越好,<strong>还有 END 这个符号</strong></p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506150925655.png" alt="image-20210506150925655" style="zoom:50%;" /></p>
<p>那这个就是 Decoder 的训练：<strong>把 Ground Truth ,正确答案给它,希望 Decoder 的输出跟正确答案越接近越好</strong></p>
<p>那这边有一件值得我们注意的事情,在<strong>训练</strong>的时候我们会给 Decoder 看<strong>正确答案</strong>,也就是我们会告诉它说</p>
<ul>
<li>在已经有 "BEGIN",在有"机"的情况下你就要输出"器"</li>
<li>有 "BEGIN" 有"机" 有"器"的情况下输出"学"</li>
<li>有 "BEGIN" 有"机" 有"器" 有"学"的情况下输出"习"</li>
<li>有 "BEGIN" 有"机" 有"器" 有"学" 有"习"的情况下,你就要输出"断"</li>
</ul>
<p>在 Decoder 训练的时候,我们会在输入的时候给它<strong>正确的答案</strong>,那这件事情叫做 ==Teacher Forcing==</p>
<p>那这个时候你马上就会有一个问题了</p>
<ul>
<li>训练的时候,Decoder 有偷看到正确答案了</li>
<li>但是测试的时候,显然没有正确答案可以给 Decoder 看</li>
</ul>
<p>刚才也有强调说在真正使用这个模型,在 Inference 的时候,Decoder 看到的是自己的输入,这<strong>中间显然有一个 ==Mismatch==</strong>,那等一下我们会有一页投影片的说明,有什麼样可能的解决方式</p>
<h2 id="tips">Tips<a class="headerlink" href="#tips" title="Permanent link">&para;</a></h2>
<p>那接下来,不侷限於 Transformer ,讲一些训练这种 Sequence To Sequence Model 的Tips</p>
<h3 id="copy-mechanism">Copy Mechanism<a class="headerlink" href="#copy-mechanism" title="Permanent link">&para;</a></h3>
<p>在我们刚才的讨论裡面,我们都要求 Decoder 自己產生输出,但是对很多任务而言,也许 <strong>Decoder 没有必要自己创造输出</strong>出来,它需要做的事情,也许是<strong>从输入的东西裡面复製</strong>一些东西出来</p>
<p>像这种复製的行為在哪些任务会用得上呢,一个例子是做聊天机器人</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506160219468.png" alt="image-20210506160219468" style="zoom: 67%;" /></p>
<ul>
<li>
<p>人对机器说:你好 我是库洛洛,</p>
</li>
<li>
<p>机器应该回答说:库洛洛你好 很高兴认识你</p>
</li>
</ul>
<p>对机器来说,它其实<strong>没有必要创造</strong>库洛洛这个词汇,这对机器来说一定会是一个非常怪异的词汇,所以它可能很难,在训练资料裡面可能一次也没有出现过,所以它不太可能正确地產生这段词汇出来</p>
<p>但是假设今天机器它在学的时候,它学到的是看到输入的时候说我是某某某,就直接把某某某,不管这边是什麼复製出来说某某某你好</p>
<p>那这样子机器的<strong>训练显然会比较容易</strong>,它显然比较有可能得到正确的结果,所以复製对於对话来说,可能是一个需要的技术 需要的能力</p>
<h3 id="summarization">Summarization<a class="headerlink" href="#summarization" title="Permanent link">&para;</a></h3>
<p>或者是在做摘要的时候,你可能更需要 Copy 这样子的技能</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506160548411.png" alt="image-20210506160548411" style="zoom:67%;" /></p>
<p>摘要就是,你要训练一个模型,然后这个<strong>模型去读一篇文章,然后產生这篇文章的摘要</strong></p>
<p>那这个任务完全是有办法做的,你就是收集大量的文章,那每一篇文章都有人写的摘要,然后你就训练一个,Sequence-To-Sequence 的 Model,就结束了</p>
<p>你要做这样的任务,<strong>只有一点点的资料是做不起来的</strong>,有的同学收集个几万篇文章,然后训练一个这样的,Sequence-To-Sequence Model,发现结果有点差</p>
<p>你要训练这种,你要叫机器说合理的句子,通常这个==百万篇文章==是需要的,所以如果你有百万篇文章,那些文章都有人标的摘要,那有时候你会把,直接把文章标题当作摘要,那这样就不需要花太多人力来标,你是可以训练一个,直接可以帮你读一篇文章,做个摘要的模型</p>
<p>对<strong>摘要</strong>这个任务而言,其实<strong>从文章裡面直接复製一些资讯出来</strong>,可能是一个很关键的能力,那 Sequence-To-Sequence Model,有没有办法做到这件事呢,那简单来说就是有,那我们就不会细讲</p>
<p>最早有从输入复製东西的能力的模型,叫做 Pointer Network</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506161130631.png" alt="image-20210506161130631" style="zoom: 67%;" /></p>
<p>那这个过去上课是有讲过的,我把<a href="https://youtu.be/VdOyqNQ9aww">录影</a>放在这边给大家参考,好 那后来还有一个变形,叫做 Copy Network,那你可以看一下这一篇,Copy Mechanism,就是 Sequence-To-Sequence,有没有问题,你看 Sequence-To-Sequence Model,是怎麼做到从输入复製东西到输出来的</p>
<h3 id="guided-attention">Guided Attention<a class="headerlink" href="#guided-attention" title="Permanent link">&para;</a></h3>
<p>机器就是一个黑盒子,有时候它裡面学到什麼东西,你实在是搞不清楚,那有时候它会犯<strong>非常低级的错误</strong></p>
<p>这边举的例子是<strong>语音合成</strong></p>
<p>你完全可以就是训练一个,Sequence-To-Sequence 的 Model,Transformer 就是一个例子</p>
<ul>
<li>收集很多的声音,文字跟声音讯号的对应关係</li>
<li>然后接下来告诉你的,Sequence-To-Sequence Model ,看到这段中文的句子,你就输出这段声音</li>
<li>然后就没有然后,就==硬 Train 一发==就结束了,然后机器就可以学会做语音合成了</li>
</ul>
<p>像这样的方法做出来结果,其实还不错,</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506161940442.png" alt="image-20210506161940442" style="zoom:67%;" /></p>
<p>举例来说我叫机器连说 4 次发财,看看它会怎麼讲,机器输出的结果是:发财 发财 发财 发财</p>
<p>就发现很神奇,我输入的发财是明明是同样的词汇,只是重复 4 次,机器居然自己有一些抑扬顿挫,它怎麼学到这件事,不知道,它自己训练出来就是这个样子</p>
<p>那你让它讲 3 次发财也没问题,那它讲 2 次发财也没问题,让它讲 1 次发财,<strong>它不念“发”</strong> </p>
<p>不知道為什麼这样子,就是你这个 Sequence-To-Sequence Model,有时候 Train 出来就是,会產生莫名其妙的结果,<strong>也许在训练资料裡面,这种非常短的句子很少</strong>,所以机器不知道要怎麼处理这种非常短的句子,你叫它念发财,它把发省略掉只念财,你居然叫它念 4 次的发财,重复 4 次没问题,叫它只念一次,居然会有问题,就是这麼的奇怪</p>
<p>当然其实这个例子并没有那麼常出现,就这个用 Sequence-To-Sequence,Learn 出来 TTS,也没有你想像的那麼差,这个要找这种差的例子也是挺花时间的,要花很多时间才找得到这种差的例子,但这样子的例子是存在的</p>
<p>所以怎麼办呢</p>
<p>我们刚才发现说机器居然<strong>漏字</strong>了,输入有一些东西它居然没有看到,我们能不能<strong>够强迫它,一定要把输入的每一个东西通通看过</strong>呢</p>
<p>这个是有可能的,这招就叫做 ==Guided Attention==</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506162647905.png" alt="image-20210506162647905" style="zoom:80%;" /></p>
<p>像语音辨识这种任务,你其实很难接受说,你讲一句话,今天辨识出来,居然有一段机器没听到,或语音合成你输入一段文字,语音合出来居然有一段没有念到,这个人很难接受</p>
<p>那如果是其它应用,比如说 Chat Bot,或者是 Summary,可能就没有那麼严格,因為对一个 Chat Bot 来说,输入后一句话,它就回一句话,它到底有没有把整句话看完,其实你 Somehow 也不在乎,你其实也搞不清楚</p>
<p>但是<strong>对语音辨识 语音合成,Guiding Attention,可能就是一个比较重要的技术</strong></p>
<p>Guiding Attention 要做的事情就是,<strong>要求机器它在做 Attention 的时候,是有固定的方式的</strong>,举例来说,对语音合成或者是语音辨识来说,我们想像中的 <strong>Attention,应该就是由左向右</strong></p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506163030902.png" alt="image-20210506163030902" style="zoom:67%;" /></p>
<p>在这个例子裡面,我们用红色的这个曲线,来代表 Attention 的分数,这个越高就代表 Attention 的值越大</p>
<p>我们以语音合成為例,那你的输入就是一串文字,那你在合成声音的时候,显然是<strong>由左念到右</strong>,所以机器应该是,先看最左边输入的词汇產生声音,再看中间的词汇產生声音,再看右边的词汇產生声音</p>
<p>如果你今天在做语音合成的时候,你发现机器的 Attention,是<strong>颠三倒四的</strong>,它先看最后面,接下来再看前面,那再胡乱看整个句子,那显然有些是做错了,显然有些是,Something is wrong,有些是做错了,</p>
<p>所以 Guiding Attention 要做的事情就是,强迫 Attention 有一个固定的样貌,那如果你对这个问题,本身就已经有理解知道说,语音合成 TTS 这样的问题,你的 Attention 的分数,Attention 的位置都应该由左向右,那不如就直接把这个限制,放进你的 Training 裡面,要求机器学到 Attention,就应该要由左向右</p>
<p>那这件事怎麼做呢,有一些关键词汇我就放在这边,让大家自己 Google 了,比如说某某 Mnotonic Attention,或 Location-Aware 的 Attention,那这个部分也是大坑,也不细讲,那就留给大家自己研究</p>
<h3 id="beam-search">Beam Search<a class="headerlink" href="#beam-search" title="Permanent link">&para;</a></h3>
<p>Beam Search ,我们这边举一个例子,在这个例子裡面我们假设说,我们现在的这个 <strong>Decoder就只能產生两个字</strong>,一个叫做 A 一个叫做 B</p>
<p>那对 Decoder 而言,它做的事情就是,<strong>每一次在第一个 Time Step,它在 A B 裡面决定一个,然后决定了 A 以后,再把 A 当做输入,然后再决定 A B 要选哪一个</strong></p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506163652097.png" alt="image-20210506163652097" style="zoom: 50%;" /></p>
<p>那举例来说,它可能选 B 当作输入,再决定 A B 要选哪一个,那在我们刚才讲的 Process 裡面,每一次 Decoder 都是选,分数最高的那一个</p>
<p>我们<strong>每次都是选Max 的那一个</strong>,所以假设 A 的分数 0.6,B 的分数 0.4,Decoder 的第一次就会输出 A,然后接下来假设 B 的分数 0.6,A 的分数 0.4,Decoder 就会输出 B,好,然后再假设把 B 当做 Input,就现在输入已经有 A 有 B 了,然后接下来,A 的分数 0.4,B 的分数 0.6,那 Decoder 就会选择输出 B,所以输出就是 A 跟 B 跟 B</p>
<p>那像这样子每次找分数最高的那个 Token,每次找分数最高的那个字,来当做输出这件事情叫做,==Greedy Decoding==</p>
<p>但是 Greedy Decoding,一定是更好的方法吗,有没有可能我们在第一步的时候,先稍微捨弃一点东西</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506164137822.png" alt="image-20210506164137822" style="zoom:50%;" /></p>
<p>比如说第一步虽然 B 是 0.4,但我们就先选 0.4 这个 B,然后接下来我们选了 B 以后,也许接下来的 B 的可能性就大增,就变成 0.9,然后接下来第三个步骤,B 的可能性也是 0.9</p>
<p>如果你比较红色的这一条路,跟绿色这条路的话,你会发现说绿色这一条路,虽然一开始第一个步骤,你选了一个比较差的输出,但是<strong>接下来的结果是好的</strong></p>
<p>这个就跟那个天龙八部的真龙棋局一样,对不对,先堵死自己一块,结果接下来反而赢了</p>
<p>那所以我,如果我们要怎麼找到,这个最好的绿色这一条路呢,也许一个可能是,<strong>爆搜所有可能的路径</strong>,但问题是我们实际上,<strong>并没有办法爆搜所有可能的路径</strong>,因為实际上每一个转捩点可以的选择太多了,如果是在对中文而言,我们中文有 4000 个字,所以这个树每一个地方分叉,都是 4000 个可能的路径,你走两三步以后,你就无法穷举</p>
<p>所以怎麼办呢,有一个演算法叫做 ==Beam Search==,它用比较有效的方法,找一个 Approximate,找一个估测的 Solution,找一个不是很精準的,不是完全精準的 Solution,这个技术叫做 Beam Search,那这个也留给大家自己 Google,好 </p>
<p>那这个 Beam Search 这个技术,到底有没有用呢,有趣的事就是,<strong>它有时候有用,有时候没有用,</strong>你会看到有些文献告诉你说,Beam Search 是一个很烂的东西</p>
<p>举例来说这篇 Paper 叫做,The Curious Case Of Neural Text Degeneration,那这个任务要做的事情是,Sentence Completion,也就是机器先读一段句子,接下来它要把这个句子的后半段,把它完成,你给它一则新闻,或者是一个故事的前半部,哇 它自己发挥它的想像创造力,把这个文章,把故事的后半部把它写完</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506164817398.png" alt="image-20210506164817398" style="zoom:67%;" /></p>
<p>那你会发现说,Beam Search 在这篇文章裡面,一开头就告诉你说,Beam Search 自己有问题：如果你用 Beam Search 的话,会发现说机器不断讲重复的话,它不断开始陷入鬼打墙 无穷迴圈,不断说重复的话</p>
<p>如果你今天不是用 Beam Search,有加一些随机性,虽然结果不一定完全好,但是看起来至少是比较正常的句子,所以有趣的事情是,有时候对 Decorder 来说,没有找出分数最高的路,反而结果是比较好的</p>
<p>这个时候你又觉得乱乱的 对不对,就是刚才前一页投影片才说,要找出分数最高的路,现在又要讲说<strong>找出分数最高的路不见得比较好</strong>,到底是怎麼回事呢</p>
<p>那其实这个就是要,<strong>看你的任务的本身的特性</strong></p>
<ul>
<li>
<p>就假设一个任务,它的<strong>答案非常地明确</strong></p>
<p>举例来说,什麼叫答案非常明确呢,比如说语音辨识,说一句话辨识的结果就只有一个可能,就那一串文字就是你唯一可能的正确答案,并没有什麼模糊的地带</p>
<p>对这种任务而言,通常 Beam Search 就会比较有帮助,那什麼样的任务</p>
</li>
<li>
<p><strong>你需要机器发挥一点创造力的时候,这时候 Beam Search 就比较没有帮助</strong>,</p>
<p>举例来说在这边的 Sentence Completion,给你一个句子,给你故事的前半部,后半部有无穷多可能的发展方式,那这种需要有一些创造力的,有不是只有一个答案的任务,往往会比较需要在 Decoder 裡面,加入随机性,还有另外一个 Decoder,也非常需要随机性的任务,叫做语音合成,TTS 就是语音合成的缩写</p>
</li>
</ul>
<p>这也许就呼应了一个英文的谚语,就是要<strong>接受没有事情是完美的,那真正的美也许就在不完美之中</strong>,对於 TTS 或 Sentence Completion 来说,Decoder 找出最好的结果,不见得是人类觉得最好的结果,反而是奇怪的结果,那你加入一些随机性,结果反而会是比较好的</p>
<h3 id="optimizing-evaluation-metrics">Optimizing Evaluation Metrics?<a class="headerlink" href="#optimizing-evaluation-metrics" title="Permanent link">&para;</a></h3>
<p>在作业裡面,我们评估的标準用的是,BLEU Score,BLEU Score 是你的 Decoder,先產生一个完整的句子以后,再去跟正确的答案一整句做比较,我们是拿两个句子之间做比较,才算出 BLEU Score</p>
<p>但我们在训练的时候显然不是这样,<strong>训练</strong>的时候,<strong>每一个词汇是分开考虑的</strong>,训练的时候,我们 Minimize 的是 Cross Entropy,Minimize Cross Entropy,真的可以 Maximize BLEU Score 吗</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506165953175.png" alt="image-20210506165953175" style="zoom: 67%;" /></p>
<p>不一定,因為这两个根本就是,它们可能有一点点的关联,但它们又没有那麼直接相关,它们根本就是两个不同的数值,所以我们 Minimize Cross Entropy,不见得可以让 BLEU Score 比较大</p>
<p>所以你发现说在助教的程式裡面,助教在做 Validation 的时候,并不是拿 Cross Entropy 来挑最好的 Model,而是挑 BLEU Score 最高的那一个 Model,所以我们训练的时候,是看 Cross Entropy,但是我们实际上你作业真正评估的时候,看的是 BLEU Score,所以你 Validation Set,其实应该考虑用 BLEU Score</p>
<p>那接下来有人就会想说,那我们能不能<strong>在 Training 的时候,就考虑 BLEU Score 呢</strong>,我们能不能够训练的时候就说,我的 Loss 就是,BLEU Score 乘一个负号,那我们要 Minimize 那个 Loss,假设你的 Loss 是,BLEU Score乘一个负号,它也等於就是 Maximize BLEU Score</p>
<p>但是<strong>这件事实际上没有那麼容易</strong>,你当然可以把 BLEU Score,当做你训练的时候,你要最大化的一个目标,但是 BLEU Score 本身很复杂,它是不能微分的,</p>
<p>这边之所以採用 Cross Entropy,而且是每一个中文的字分开来算,就是因為这样我们才有办法处理,如果你是要计算,两个句子之间的 BLEU Score,这一个 Loss,根本就没有办法做微分,那怎麼办呢</p>
<p>这边就教大家一个口诀,遇到你在 Optimization 无法解决的问题,==用 RL 硬 Train 一发==就对了这样,遇到你无法 Optimize 的 Loss Function,把它当做是 RL 的 Reward,把你的 Decoder 当做是 Agent,它当作是 RL,Reinforcement Learning 的问题硬做</p>
<p>其实也是有可能可以做的,<strong>有人真的这样试过</strong>,我把 Reference 列在这边给大家参考,当然这是一个比较难的做法,那并没有特别推荐你在作业裡面用这一招</p>
<h3 id="scheduled-sampling">Scheduled Sampling<a class="headerlink" href="#scheduled-sampling" title="Permanent link">&para;</a></h3>
<p>那我们要讲到,我们刚才反覆提到的问题了,就是<strong>训练跟测试居然是不一致</strong>的</p>
<p>测试的时候,Decoder 看到的是自己的输出,所以测试的时候,Decoder 会看到一些错误的东西,但是在训练的时候,Decoder 看到的是完全正确的,那这个不一致的现象叫做,==Exposure Bias==</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506170906750.png" alt="image-20210506170906750" style="zoom:67%;" /></p>
<p>假设 Decoder 在训练的时候,永远只看过正确的东西,那在测试的时候,你只要有一个错,那就会<strong>一步错 步步错</strong>,因為对 Decoder 来说,它从来没有看过错的东西,它看到错的东西会非常的惊奇,然后接下来它產生的结果可能都会错掉</p>
<p>所以要怎麼解决这个问题呢</p>
<p>有一个可以的思考的方向是,<strong>给 Decoder 的输入加一些错误的东西</strong>,就这麼直觉,你不要给 Decoder 都是正确的答案,偶尔给它一些错的东西,它反而会学得更好,这一招叫做,==Scheduled Sampling==,它不是那个 Schedule Learning Rate,刚才助教有讲 Schedule Learning Rate,那是另外一件事,不相干的事情,这个是 Scheduled Sampling</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506171120911.png" alt="image-20210506171120911" style="zoom:67%;" /></p>
<p>Scheduled Sampling 其实很早就有了,这个是 15 年的 Paper,很早就有 Scheduled Sampling,在还没有 Transformer,只有 LSTM 的时候,就已经有 Scheduled Sampling,但是 Scheduled Sampling 这一招,它其实会伤害到,Transformer 的平行化的能力,那细节可以再自己去了解一下,所以对 Transformer 来说,它的 Scheduled Sampling,另有招数跟传统的招数,跟原来最早提在,这个 LSTM上被提出来的招数,也不太一样,那我把一些 Reference 的,列在这边给大家参考</p>
<p><img src="https://gitee.com/unclestrong/deep-learning21_note/raw/master/imgbed/image-20210506171143270.png" alt="image-20210506171143270" style="zoom:67%;" /></p>
<p>好 那以上我们就讲完了,Transformer 和种种的训练技巧,这个我们已经讲完了 Encoder,讲完了 Decoder,也讲完了它们中间的关係,也讲了怎麼训练,也讲了种种的 Tip</p>





                
              </article>
            </div>
          
          
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            回到页面顶部
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 hlx
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    <a href="https://space.bilibili.com/387119156" target="_blank" rel="noopener" title="Bilibili | 少年寥若晨星" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M488.6 104.1c16.7 18.1 24.4 39.7 23.3 65.7v202.4c-.4 26.4-9.2 48.1-26.5 65.1-17.2 17-39.1 25.9-65.5 26.7H92.02c-26.45-.8-48.21-9.8-65.28-27.2C9.682 419.4.767 396.5 0 368.2V169.8c.767-26 9.682-47.6 26.74-65.7C43.81 87.75 65.57 78.77 92.02 78h29.38L96.05 52.19c-5.75-5.73-8.63-13-8.63-21.79 0-8.8 2.88-16.06 8.63-21.797C101.8 2.868 109.1 0 117.9 0s16.1 2.868 21.9 8.603L213.1 78h88l74.5-69.397C381.7 2.868 389.2 0 398 0c8.8 0 16.1 2.868 21.9 8.603 5.7 5.737 8.6 12.997 8.6 21.797 0 8.79-2.9 16.06-8.6 21.79L394.6 78h29.3c26.4.77 48 9.75 64.7 26.1zm-38.8 69.7c-.4-9.6-3.7-17.4-10.7-23.5-5.2-6.1-14-9.4-22.7-9.8H96.05c-9.59.4-17.45 3.7-23.58 9.8-6.14 6.1-9.4 13.9-9.78 23.5v194.4c0 9.2 3.26 17 9.78 23.5s14.38 9.8 23.58 9.8H416.4c9.2 0 17-3.3 23.3-9.8 6.3-6.5 9.7-14.3 10.1-23.5V173.8zm-264.3 42.7c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.2 6.3-14 9.5-23.6 9.5-9.6 0-17.5-3.2-23.6-9.5-6.1-6.3-9.4-14-9.8-23.2v-33.3c.4-9.1 3.8-16.9 10.1-23.2 6.3-6.3 13.2-9.6 23.3-10 9.2.4 17 3.7 23.3 10zm191.5 0c6.3 6.3 9.7 14.1 10.1 23.2V273c-.4 9.2-3.7 16.9-9.8 23.2-6.1 6.3-14 9.5-23.6 9.5-9.6 0-17.4-3.2-23.6-9.5-7-6.3-9.4-14-9.7-23.2v-33.3c.3-9.1 3.7-16.9 10-23.2 6.3-6.3 14.1-9.6 23.3-10 9.2.4 17 3.7 23.3 10z"/></svg>
    </a>
  
    
    
    <a href="https://github.com/a-hlx" target="_blank" rel="noopener" title="GitHub | a-hlx" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.top", "navigation.indexes", "navigation.expand", "search.suggest", "search.highlight"], "search": "../../../../assets/javascripts/workers/search.e5c33ebb.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.51d95adb.min.js"></script>
      
        <script src="../../../../mkdocs/javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>