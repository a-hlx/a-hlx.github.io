## 前言

数据集的构建包括：数据集采集、数据集打标签、数据集清洗、数据集预处理、数据集读取。

数据集采集有**爬虫**

数据集打标签有[Labelme](https://zhuanlan.zhihu.com/p/112512069)**、**[Labelimg](https://zhuanlan.zhihu.com/p/90832346)

数据集清洗、预处理有**numpy、pandas**

数据集读取有**Dataset、ImageFolder**


**数据集读取**是比较考验代码能力的，本文将详细介绍各类数据集读取的过程及标准代码模板。

## 训练/验证/测试集

### one
搭建合理的训练验证集和测试集能加速网络的形成，也更有效的衡量算法偏差和方差。  
在配置训练，验证，测试数据集过程中做出正确决策。分别作用如下：

验证集：验证选择模型。测试集：正确评估分类器的性能即对网络系统做出无偏评估

具体过程：  
通过训练集执行训练算法，通过验证集选择最好的模型，充分验证确定好模型后就可以在测试集上进行评估，为了无偏评估算法在小数据时代常见的做法是将数据三七分。

一般数据量在1000，10000等级时如下分配即可：70%的训练集，30%的测试集，如果没有明确设置验证集，也可以60%训练集，20%验证集，20%测试集。

在大数据的今天数据量是百万级别的，验证集和测试集占数据总量的比列趋向于更小。

比如有100万条数据，拿出1万作为验证集即可，找出最好的1-2个模型，同样根据选择的分类器，1万条数据便可评估单个分类器，此时的比列为98%，1%，1%。数据量越大比列可能更小。

关于数据集的划分要注意的几个问题：  
1.要确保验证集和测试集数据来自同一分布  
同一分布的理解：数据一，分辨率高，像素高，数据二 分辨率低，像素低，数据一二 属于不同分布。

2.也可以没有测试集（若无需做无偏评估）  
在训练集上训练，验证集上评估，因为验证集已经涵盖测试集数据，这种情况验证集被称为测试集。

搭建合理的训练验证集和测试集能加速网络的形成，也更有效的衡量算法偏差和方差。我们在下一篇博客中讲解偏差和方差。

### two
**train**是[训练集](https://so.csdn.net/so/search?q=%E8%AE%AD%E7%BB%83%E9%9B%86&spm=1001.2101.3001.7020)，**val**是训练过程中的测试集，是为了让你在边训练边看到训练的结果，及时判断学习状态。**test**就是训练模型结束后，用于评价模型结果的测试集。只有train就可以训练，val不是必须的，比例也可以设置很小。test对于[model](https://so.csdn.net/so/search?q=model&spm=1001.2101.3001.7020)训练也不是必须的，但是一般都要预留一些用来检测，通常推荐比例是8:1:1

`val`是`validation`的简称。  
`training dataset`和`validation dataset`都是在训练的时候起作用。  
而因为`validation`的数据集和`training`没有交集，所以这部分数据对最终训练出的模型没有贡献。  
**`validation`的主要作用是来验证是否过拟合、以及用来调节训练参数等。**

比如训练`0-10000`次迭代过程中，`train`和`validation`的`loss`都是不断降低，  
但是从`10000-20000`过程中`train loss`不断降低，`validation`的`loss`不降反升。  
那么就证明继续训练下去，模型只是对`training dataset`这部分拟合的特别好，但是泛化能力很差。  
所以与其选取`20000`次的结果，不如选择`10000`次的结果。  
这个过程的名字叫做`Early Stop`，`validation`数据在此过程中必不可少。


## 图像分类数据集

### 数据组织

采集图片数据集，创建以下目录

> IMAGEDATA----------------根目录  
> IMAGEDATA/train----------训练集  
> IMAGEDATA/test-----------测试集  
> IMAGEDATA/val------------验证集

![](https://pic1.zhimg.com/v2-8cd2b666de94996d017ecf7ed509100c_b.jpg)

IMAGEDATA

在**train/test/val**文件夹下创建**dog、cat**文件夹

> IMAGEDATA/train/cat----------训练集/猫  
> IMAGEDATA/train/dog---------训练集/狗  
> IMAGEDATA/test/cat-----------测试集/猫  
> IMAGEDATA/test/dog----------测试集/狗  
> IMAGEDATA/val/cat------------验证集/猫  
> IMAGEDATA/val/dog-----------验证集/狗

![](https://pic2.zhimg.com/v2-43ed9bb7613562278623a3b0b6cb1f85_b.jpg)

在**dog、cat**文件夹下分别存放对应的图片数据

![](https://pic3.zhimg.com/v2-ff4ee7aef1acf82e0fa69e432dec6a9e_b.jpg)

在**.txt文件**中指明图片数据与标签的关系：0代表猫；1代表狗。

> IMAGEDATA/train/train.txt----------训练集  
> IMAGEDATA/test/tset.txt----------测试集  
> IMAGEDATA/val/val.txt----------验证集

![](https://pic4.zhimg.com/v2-fdfa0458fa932c79aa96d5f4f6aee4c7_b.jpg)

.txt文件

### 数据读取

按照上述方式组织好数据集后，我们将利用**torch.utils.data**进行数据集读取，用于模型训练、测试。

数据集读取主要使用**torch.utils.data**库中的**Dataset、DataLoader**两个类。

自定义数据集读取必须继承**Dataset类，**且必须重写该类的**\_\_len\_\_( )、\_\_getitem\_\_( )** 两个方法。

> \_\_len\_\_( )：获取数据集大小的方法  
> \_\_getitem( )：提供下标索引方式访问数据集的方法

数据读取的具体代码实现如下：

-   制作存储了图片和标签路径的.txt文件
-   将txt文件信息转换为list，该list每一个元素对应一个样本
-   通过getitem函数读取数据和标签，并返回数据和标签

1.导入python包

```
import numpy as np
from skimage import io
from skimage import transform
import matplotlib.pyplot as plt
import os 
import torch
from torch.utils.data import Dataset,DataLoader
from torchvision.transforms import transforms
```

2.定义数据集读取类，继承Dataset

```
class MyDataset(Dataset):
    def __init__(self,root_dir,names_file,transform=None):
        self.root_dir = root_dir #根目录
        self.names_file = names_file #.txt文件路径
        self.transform = transform #数据预处理
        self.size = 0 #数据集大小
        self.names_list = [] #数据集路径列表
        
        if not os.path.isfile(self.names_file):
            print(self.names_file + 'does not exist!')
        file = open(self.names_file)
        for f in file: #循环读取.txt文件总每行数据信息
            self.names_list.append(f)
            self.size += 1
        
    def __len__(self):
        return self.size
    
    def __getitem__(self,index):
        image_path = self.root_dir + self.names_list[index].split(' ')[0] #获取图片数据路径
        if not os.path.isfile(image_path):
            print(image_path + 'does not exist!')
            return None
        image = io.imread(image_path) #读取图片
        label = int(self.names_list[index].split(' ')[1]) #读取标签
 
        return image,label
        
        #sample = {'image':image,'label':lable}
        #if self.transform:
        #    sample = self.transform(sample) 
            
        #return sample #返回图片及对应的标签
```

3\. 实例化数据读取类，利用**DataLoader**封装为可迭代对象

```
train_dataset = MyDataset(root_dir='./IMAGEDATA/train',names_file='./IMAGEDATA/train/train.txt',transform=None)

trainset_dataloader = DataLoader(dataset=train_dataset,batch_size=4,shuffle=True,num_workers=4)
```

**注：**用于训练、验证、测试的数据和标签必须先转换为**Tensor**数据结构（transform.ToTensor）才能送入模型进行训练、验证、测试。

## 目标识别数据集

目标检测数据集与图像分类数据集的唯一区别在于**标签**：图像分类的标签是数字，目标检测的标签是列表。

![](https://pic2.zhimg.com/v2-1da4746b7c3a2b903f4bc72cbe76e92d_b.jpg)

标签差别

### 数据组织

采集图片数据，创建以下文件夹

> DetectionData/Annotations------------存放标注后的xml文件  
> DetectionData/ImageSets--------------存放训练集、验证集、测试集的文件列表  
> DNetectionData/JPEFGImages------------存放原始图片

利用**labelimg**对图片进行标注，并将标注后的xml文件存放至Annotions

执行以下代码，划分数据集:

```
import os
import random

path=' '

trainval_percent = 0.66
train_percent = 0.5

xmlfilepath = path+'Annotations'
txtsavepath = path+'ImageSets'
total_xml = os.listdir(xmlfilepath)
 
num=len(total_xml)
list=range(num)
tv=int(num*trainval_percent)
tr=int(tv*train_percent)
trainval= random.sample(list,tv)
train=random.sample(trainval,tr)
 
ftrainval = open(path+'ImageSets/trainval.txt', 'w')
ftest = open(path+'ImageSets/test.txt', 'w')
ftrain = open(path+'ImageSets/train.txt', 'w')
fval = open(path+'ImageSets/val.txt', 'w')
 
for i  in list:
    name=total_xml[i][:-4]+'\n'
    if i in trainval:
        ftrainval.write(name)
        if i in train:
            ftrain.write(name)
        else:
            fval.write(name)
    else:
        ftest.write(name)
 
ftrainval.close()
ftrain.close()
fval.close()
ftest .close()
```

### 数据读取

```
import torch
import PIL
from PIL import Image
import numpy as np
from torchvision.transforms import transforms

class MyDataset(torch.utils.data.Dataset):
    def __init__(self,images_path,labels_path,Transform=None):
        
        #1.所有图片和标签的路径
        images_path_list = []
        labels_path_list = []
        
        #获取image/label路径的代码
        self.images_path_list = images_path_list
        self.labels_path_list = labels_path_list
        self.transform = Transform
        
    def __getitem__(self,index):
        
        #2.根据index取得一个样本的数据、标签路径
        image_path = image_path_list[index]
        label_path = image_path_list[index]
        
        #3.读取数据和标签
        image = Image.open(image_path).convert('RGB')
        label = Image.open(image_path).convert('L')
        
        #4.对数据和标签进行转换
        if self.transform is not None:
            image = self.transform(image)
            label = self.transform(label)
            
        return image,label
    
    def __len__(self):
        return len(self.images_path_list)

img_path = ' '
label_path = ' '

dataset = MyDataset(img_path,label_path,transform=transform.ToTensor())
```

## 语义分割数据集

语义分割数据集与图像分类数据集的唯一区别在于**标签**：图像分类的标签是数字，而语义分割的标签是图片。

![](https://pic2.zhimg.com/v2-6a55ce53e96b8d5980b022a3afbb10f1_b.jpg)

标签差别

### 数据组织

采集图片数据，保存至以下菜单中

> SegmentData-------------根目录  
> SegmentData/before---------图片数据

![](https://pic1.zhimg.com/v2-e3ff793417ad128c52beab7cae6b57b8_b.jpg)

图片存储路径

利用**labelme**对图片进行标注并将生成的.json数据保存至**before**文件夹中

![](https://pic3.zhimg.com/v2-c4da994236476e35764b930ccce8e01a_b.jpg)

.json文件

.json文件存储了图片类别名，以及标注点集

![](https://pic2.zhimg.com/v2-2c9ccb3f571b5894804b2ce7820d15dd_b.jpg)

执行以下代码，将json文件生成对应的标注文件

```
import argparse
import json
import os
import os.path as osp
import warnings
import imgviz
import PIL.Image
import yaml
 
from labelme import utils
import base64

def main():
    
    before_path = 'C:/Users/YY/Desktop/SegmentData/before/'  #存放原始图片和josn文件的路径
    output_path = 'C:/Users/YY/Desktop/SegmentData/'  #output文件夹的路径
    
    count = os.listdir(before_path)
    for i in range(0,len(count)):
        path = os.path.join(before_path,count[i])
        
        if os.path.isfile(path) and path.endswith('json'):
            data = json.load(open(path))
            
            if data['imageData']:
                imageData = data['imageData']
            else:
                imagePath = os.path.join(os.path.dirname(path),data['imagePath'])
                with open(imagePath,'rb') as f:
                    imageData = f.read()
                    imageData = base64.b64encode(imageData).decode('utf-8')
            img = utils.img_b64_to_arr(imageData)
            label_name_to_value = {'_background_':0}
            for shape in data['shapes']:
                label_name = shape['label']
                if label_name in label_name_to_value:
                    label_value = len(label_name_to_value)
                else:
                    label_value = len(label_name_to_value)
                    label_name_to_value[label_name] = label_value
            
            # label_values must be dense
            label_values, label_names = [], []
            for ln, lv in sorted(label_name_to_value.items(), key=lambda x: x[1]):
                label_values.append(lv)
                label_names.append(ln)
            assert label_values == list(range(len(label_values)))
            
            lbl, _ = utils.shapes_to_label(img.shape, data['shapes'], label_name_to_value)
 
            # captions = ['{}: {}'.format(lv, ln)
            #     for ln, lv in label_name_to_value.items()]
            # lbl_viz = utils.labelme_shapes_to_label(lbl, img, captions)
            label_names = [None] * (max(label_name_to_value.values()) + 1)
            for name, value in label_name_to_value.items():
                label_names[value] = name
 
            lbl_viz = imgviz.label2rgb(
                lbl, imgviz.asgray(img), label_names=label_names, loc="rb"
            )
 
            out_dir = osp.basename(count[i]).replace('.', '_')
            out_dir = osp.join(osp.dirname(count[i]), out_dir)
            out_dir = osp.join(output_path+"output",out_dir)
    
            if not osp.exists(out_dir):
                os.mkdir(out_dir)
            # image
            PIL.Image.fromarray(img).save(osp.join(out_dir, 'img.png'))
            # label.png
            utils.lblsave(osp.join(out_dir, 'label.png'), lbl)
            # PIL.Image.fromarray(lbl_viz).save(osp.join(out_dir, 'label_viz.png'))
            # label_viz.png
            PIL.Image.fromarray(lbl_viz).save(osp.join(out_dir, "label_viz.png"))
 
            with open(osp.join(out_dir, 'label_names.txt'), 'w') as f:
                for lbl_name in label_names:
                    f.write(lbl_name + '\n')
 
            # warnings.warn('info.yaml is being replaced by label_names.txt')
            # info = dict(label_names=label_names)
            # with open(osp.join(out_dir, 'info.yaml'), 'w') as f:
            #     yaml.safe_dump(info, f, default_flow_style=False)
 
            print('Saved to: %s' % out_dir)
 
if __name__ == '__main__':
    main()
```

![](https://pic3.zhimg.com/v2-99a6770fd27705f8fadbdd766b292166_b.jpg)

转换json文件

> img.png-------原始图片  
> label.png------语义图片  
> label\_names.txt------图片中包含的类别信息  
> label\_vis.png---------标注可视化（防止标注错误）

此时的标签只是图片包含类别的**局部标注信息**，需要转换为**全局类别标签**

在before文件夹下创建创建一个包含全局类别的txt文件**class\_name.txt**

![](https://pic2.zhimg.com/v2-8f22e8b8625486eb32b77ac0a379ba55_b.jpg)

class\_name.txt文件

执行以下代码，进行全局类别标签转换

```
import os 
from PIL import Image
import numpy as np

root = os.getcwd()
root = os.path.join(root,'SegmentData')

before = os.path.join(root,'before')
output = os.path.join(root,'output')

assert(os.path.exists(before)),'please check before floder'
assert(os.path.exists(output)),'please check output floder'
jpg = os.path.join(root,'jpg')
png = os.path.join(root,'png')
if not os.path.exists(jpg):
    os.mkdir(jpg)
if not os.path.exists(png):
    os.mkdir(png)
    
def main():
    count = os.listdir(before)
    for i in range(0,len(count)):
        if count[i].endswith('jpg'):
            path = os.path.join(before,count[i])
            img = Image.open(path)
            img.save(os.path.join(jpg,count[i]))
            
            path = output+'/'+count[i].split('.')[0]+'_json/label.png'
            img = Image.open(path)
            
            class_txt = open(before+'/class_name.txt','r')
            class_name = class_txt.read().splitlines()
            
            with open(output+'/'+count[i].split('.')[0]+'_json/label_names.txt','r') as f:
                names = f.read().splitlines()
                new = Image.new('P',(img.width,img.height))
                
                for name in names:
                    index_json = names.index(name)
                    index_all = class_name.index(name)
                    new = new+(index_all*(np.array(img)==index_json))
                
            new = Image.fromarray(np.uint8(new))
            new.save(os.path.join(png,count[i].replace('jpg','png')))
            print(np.max(new),np.min(new))
            
if __name__ == '__main__':
    main()
```

![](https://pic1.zhimg.com/v2-a06584c6c8bdd0633eeec8f18ae040a4_b.jpg)

最终数据组织

> before-------原始图片和标注的json文  
> jpg----------原始图片  
> output------局部标注文件  
> png---------全局标注文件（用于最终的训练）

### 数据读取

```
import torch
import PIL
from PIL import Image
import numpy as np
from torchvision.transforms import transforms

class MyDataset(torch.utils.data.Dataset):
    def __init__(self,images_path,labels_path,Transform=None):
        
        #1.所有图片和标签的路径
        images_path_list = []
        labels_path_list = []
        
        #获取image/label路径的代码
        self.images_path_list = images_path_list
        self.labels_path_list = labels_path_list
        self.transform = Transform
        
    def __getitem__(self,index):
        
        #2.根据index取得一个样本的数据、标签路径
        image_path = image_path_list[index]
        label_path = image_path_list[index]
        
        #3.读取数据和标签
        image = Image.open(image_path).convert('RGB')
        label = Image.open(image_path).convert('L')
        
        #4.对数据和标签进行转换
        if self.transform is not None:
            image = self.transform(image)
            label = self.transform(label)
            
        return image,label
    
    def __len__(self):
        return len(self.images_path_list)

img_path = ' '
label_path = ' '

dataset = MyDataset(img_path,label_path,transform=transform.ToTensor())
```

## 胡思乱想

深度学习前期的数据集准备是需要我们费心费力的，因为数据决定模型性能的上限！