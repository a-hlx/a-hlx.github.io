## 线性回归+基础优化算法

- [线性回归+基础优化算法](#线性回归基础优化算法)
  - [1.线性回归](#1线性回归)
  - [2.基础优化算法](#2基础优化算法)
  - [3.线性回归的从零开始实现](#3线性回归的从零开始实现)
  - [4.新型回归的简洁实现](#4新型回归的简洁实现)
  - [5.- 线性回归+基础优化算法](#5--线性回归基础优化算法)

### 1.线性回归

- 房价预测例子

- **线性模型**

  - 输入：$x=[x_1,x_2,...,x_n]^T$

  - 线性模型需要确定一个n维权重和一个标量偏差$\omega=[\omega_1,\omega_2,...,\omega_n]^T,b$

  - 输出 ：$y=\omega_1x_1+\omega_2x_2+...+\omega_nx_n+b$，

    向量版本的是 $y=<\omega,x>+b$

  - 线性模型可以看作是单层神经网络（图片）

    >- 神经网络源于神经科学（图片）
    >  - 最早的神经网络是源自神经科学的，但是时至今日，很多神经网络已经远远高于神经科学，可解释性也不是很强，不必纠结

- 衡量估计质量

  - 我们需要估计模型的预估值和真实值之间的差距，例如房屋售价和股价

  - 假设$y$是真实值，$\tilde{y}$是估计值，我们可以比较

    $l(y,\tilde{y})=\frac{1}{2}(y-\tilde{y})^2$，这个叫做**平方损失**

- **训练数据**

  - 收集一些数据点来决定参数值（权重$\omega$和偏差$b$），例如6个月内被卖掉的房子。

  - 这被称之为训练数据

  - 通常越多越好。需要注意的是，现实世界的数据都是有限的，但是为了训练出精确的参数往往需要训练数据越多越好，当训练数据不足的时候，我们还需要进行额外处理。

  - 假设我们有n个样本，记为

    $X=[x_1,x_2,...,x_n]^T,y=[y_1,y_2,...y_n]^T$

    $X$的每一行是一个样本，$y$的每一行是一个输出的实数值。

- **参数学习**

  - **训练损失**。但我们训练参数的时候，需要定义一个损失函数来衡量参数的好坏，应用前文提过的平方损失有公式：

    ​	$l(X,x,\omega,b)=\frac{1}{2n}\sum_{i=1}^n(y_i-<x_i,w>-b)^2=\frac{1}{2n}||y-X\omega-b||^2$

  - **最小化损失来学习参数**。训练参数的目的就是使损失函数的值尽可能小（这意味着预估值和真实值更接近）。最后求得的参数值可表示为：

    $\omega^*,b^*=argmin_{\omega,b}l(X,x,\omega,b)$

- **显示解**

  - 线性回归有显示解，即可以直接矩阵数学运算，得到参数w和b的最优解，而不是用梯度下降，牛顿法等参数优化方式一点点逼近最优解。

  - **推导过程**：

    - 为了方便矩阵表示和计算，将偏差加入权重，$X\gets[X,1],\omega\gets[\omega,b]$

    - 损失函数是凸函数，最优解满足导数为0，可解出显示解

      令$\frac{\partial}{\partial\omega} l(X,y,\omega)=0$

      有$\frac{1}{n}(y-X\omega)^TX=0$

      解得$\omega^*=(X^TX)^{-1}X^Ty$

- 总结
 
  - 线性回归是对n维输入的加权，外加偏差
  - 使用**平方损失**来衡量预测值和真实值之间的误差
  - **线性回归有显示解**
  - 线性回归可以看作单层神经网络



### 2.基础优化算法

- **梯度下降**

  - 当模型没有显示解的时候，应用梯度下降法逼近最优解。
  - 梯度下降法的具体步骤：
    - 挑选一个初始值$\omega_0$
    - 重复迭代参数t=1,2,3，迭代公式为：
      **$\omega_{t}=\omega_{t-1}-\eta\frac{\partial l}{\partial\omega_{t-1}}$为函数值下降最快的方向，学习率$\eta$。
  - 选择学习率
    - 学习率$\eta$为学习步长超参数，代表了沿负梯度方向走了多远（人为指定的的值，不是训练得到的）
    - 学习率不能太大，也不能太小，需要选取适当。

- **小批量随机梯度下降**

  - 在整个训练集上算梯度太贵了

    - 在实际应用中，很少直接应用梯度下降法，这是因为每次更新都需要计算训练集上所有的样本，耗费时间太长。一个深度神经网络模型，迭代一次可能需要数分钟甚至数小时。

  - 为了减少运算代价，我们可以==随机采样==b个样本$i_1,i_2,...,i_b$来近似损失，损失函数为：

    ​	$\frac{1}{b}\sum_{i\in I_b}l(x_i,y_i,\omega)$ , 

    其中**b是批量大小(batch size)，也是超参数**

  - **选择批量大小**
    
    - b也不能太大：内存消耗增加；浪费计算资源，一个极端的情况是可能会重复选取很多差不多的样本，浪费计算资源
    - b也不能太小：每次计算量太小，很难以并行，不能最大限度利用GPU资源

- **总结**

  - 梯度下降通过不断**沿着负梯度方向**更新参数求解
  - 小批量随机梯度下降是深度学习默认的求解算法（简单，稳定）
  - **两个重要的超参数：批量大小（batch size），学习率（$\eta$）**

### 3.线性回归的从零开始实现

- 代码

#### 生成数据集
将根据带有噪声的线性模型构造一个人造数据集

#### 读取数据集

练模型时要对数据集进行遍历，每次抽取一小批量样本，并使用它们来更新我们的模型。 由于这个过程是训练机器学习算法的基础，所以有必要定义一个函数， 该函数能打乱数据集中的样本并以小批量方式获取数据

定义一个`data_iter`函数， 该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为`batch_size`的小批量。 每个小批量包含一组特征和标签。

#### 初始化模型参数

通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0。

==引入自动微分来计算梯度==
在初始化参数之后，我们的任务是更新这些参数，直到这些参数足够拟合我们的数据。 每次更新都需要计算损失函数关于模型参数的梯度。 有了这个梯度，我们就可以向减小损失的方向更新每个参数。

#### 定义模型

#### 定义损失函数

平方损失函数

#### 定义优化算法（小批量随机梯度下降）

使用从数据集中随机抽取的一个小批量，然后根据参数计算损失的梯度。 接下来，朝着减少损失的方向更新我们的参数。 下面的函数实现小批量随机梯度下降更新。 该函数接受模型参数集合、学习速率和批量大小作为输入。每 一步更新的大小由学习速率`lr`决定。 因为我们计算的损失是一个批量样本的总和，所以我们用批量大小（`batch_size`） 来规范化步长，这样步长大小就不会取决于我们对批量大小的选择。

#### 训练

在每次迭代中，我们读取一小批量训练样本，并通过我们的模型来获得一组预测。 计算完损失后，我们开始反向传播，存储每个参数的梯度。 最后，我们调用优化算法`sgd`来更新模型参数。

在每个_迭代周期_（epoch）中，我们使用`data_iter`函数遍历整个数据集， 并将训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。 这里的迭代周期个数`num_epochs`和学习率`lr`都是超参数，分别设为3和0.03。


### 4.新型回归的简洁实现

- 代码

#### 读取数据集

调用框架中现有的API来读取数据。 我们将`features`和`labels`作为API的参数传递，并通过数据迭代器指定`batch_size`。 此外，布尔值`is_train`表示是否希望数据迭代器对象在每个迭代周期内打乱数据。

```python
def load_array(data_arrays, batch_size, is_train=True):  #@save
    """构造一个PyTorch数据迭代器"""
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

batch_size = 10
data_iter = load_array((features, labels), batch_size)
```

#### 定义模型

首先定义一个模型变量`net`，它是一个`Sequential`类的实例。 `Sequential`类将多个层串联在一起。 当给定输入数据时，`Sequential`实例将数据传入到第一层， 然后将第一层的输出作为第二层的输入，以此类推。 在下面的例子中，我们的模型只包含一个层，因此实际上不需要`Sequential`。 但是由于以后几乎所有的模型都是多层的，在这里使用`Sequential`会让你熟悉“标准的流水线”。

这一单层被称为_全连接层_（fully-connected layer）， 因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。

在PyTorch中，全连接层在`Linear`类中定义。 值得注意的是，我们将两个参数传递到`nn.Linear`中。 第一个指定输入特征形状，即2，第二个指定输出特征形状，输出特征形状为单个标量，因此为1。

```python
# nn是神经网络的缩写
from torch import nn

net = nn.Sequential(nn.Linear(2, 1))
```

#### 初始化模型参数

指定每个权重参数应该从均值为0、标准差为0.01的正态分布中随机采样， 偏置参数将初始化为零。
正如我们在构造`nn.Linear`时指定输入和输出尺寸一样， 现在我们能直接访问参数以设定它们的初始值。 我们通过`net[0]`选择网络中的第一个图层， 然后使用`weight.data`和`bias.data`方法访问参数。 我们还可以使用替换方法`normal_`和`fill_`来重写参数值。

```python
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)
```

#### 定义损失函数

计算均方误差使用的是`MSELoss`类，也称为平方L2范数。 默认情况下，它返回所有样本损失的平均值。

```python
loss = nn.MSELoss()
```

#### 定义优化算法

小批量随机梯度下降算法是一种优化神经网络的标准工具， PyTorch在`optim`模块中实现了该算法的许多变种。 当我们实例化一个`SGD`实例时，我们要指定优化的参数 （可通过`net.parameters()`从我们的模型中获得）以及优化算法所需的超参数字典。 小批量随机梯度下降只需要设置`lr`值，这里设置为0.03。

```python
trainer = torch.optim.SGD(net.parameters(), lr=0.03)
```

#### 训练

回顾一下：在每个迭代周期里，我们将完整遍历一次数据集（`train_data`）， 不停地从中获取一个小批量的输入和相应的标签。 对于每一个小批量，我们会进行以下步骤:

-   通过调用`net(X)`生成预测并计算损失`l`（前向传播）。
    
-   通过进行反向传播来计算梯度。
    
-   通过调用优化器来更新模型参数。
    

为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。

```python
num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X) ,y)
        trainer.zero_grad()
        l.backward()
        trainer.step()
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {l:f}')
```

下面我们比较生成数据集的真实参数和通过有限数据训练获得的模型参数。 要访问参数，我们首先从`net`访问所需的层，然后读取该层的权重和偏置。

```python
w = net[0].weight.data
print('w的估计误差：', true_w - w.reshape(true_w.shape))
b = net[0].bias.data
print('b的估计误差：', true_b - b)
```


### 5.- [线性回归+基础优化算法](#线性回归基础优化算法)
  - [1.线性回归](#1线性回归)
  - [2.基础优化算法](#2基础优化算法)
  - [3.线性回归的从零开始实现](#3线性回归的从零开始实现)
  - [4.新型回归的简洁实现](#4新型回归的简洁实现)
  - [5.QA](#5qa)QA

- **1.为什么使用平方损失而不是绝对差值？**
  - 其实差别不大，最开始使用平方损失是因为它可导，现在其实都可以使用。
- **2.损失为什么要求平均？**
  - 本质上没有关系，但是如果不求平均，梯度的数值会比较大，这时需要学习率除以n。如果不除以n，可能会随着样本数量的增大而让梯度变得很大。
- **3.不管是梯度下降还是随机梯度下降，怎么找到合适的学习率？**
  - 选择对学习率不敏感的优化方法，比如Adam
  - 合理参数初始化
- **4.训练过程中，过拟合和欠拟合情况下，学习率和batch_size应该如何调整？**
  - 理论上学习率和batch_size对最后的拟合结果不会有影响
- **5.深度学习上，设置损失函数的时候，需要考虑正则吗？**
  - 会考虑，但是和损失函数是分开的，深度学习中正则没有太大的用处，有很多其他的技术可以有正则的效果。
- **6.如果样本大小不是批量数的整数倍，需要随机剔除多余的样本吗？**
  - 就取多余的样本作为一个批次
  - 直接丢弃
  - 从下一个epoch里面补少的样本
